{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "BERTのファインチューニング事例（日本語sentense piece）livedoor記事の分類問題",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "YPk_eLIFtaNf",
        "XuHaey4RtaPx"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/murakami-tatsumi/colab/blob/master/BERT%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%B3%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E4%BA%8B%E4%BE%8B%EF%BC%88%E6%97%A5%E6%9C%AC%E8%AA%9Esentense_piece%EF%BC%89livedoor%E8%A8%98%E4%BA%8B%E3%81%AE%E5%88%86%E9%A1%9E%E5%95%8F%E9%A1%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPk_eLIFtaNf",
        "colab_type": "text"
      },
      "source": [
        "## Finetuning of the pretrained Japanese BERT model\n",
        "\n",
        "yoheikikutaさんの下記githubタスクを再現<br>\n",
        "https://github.com/yoheikikuta/bert-japanese/blob/master/notebook/finetune-to-livedoor-corpus.ipynb\n",
        "\n",
        "Finetune the pretrained model to solve multi-class classification problems.  \n",
        "This notebook requires the following objects:\n",
        "- trained sentencepiece model (model and vocab files)\n",
        "- pretraiend Japanese BERT model\n",
        "\n",
        "Dataset is livedoor ニュースコーパス in https://www.rondhuit.com/download.html.  \n",
        "We make test:dev:train = 2:2:6 datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiJNS0GYtaNh",
        "colab_type": "text"
      },
      "source": [
        "Results:\n",
        "\n",
        "- Full training data\n",
        "  - BERT with SentencePiece\n",
        "    ```\n",
        "                    precision    recall  f1-score   support\n",
        "\n",
        "    dokujo-tsushin       0.98      0.94      0.96       178\n",
        "      it-life-hack       0.96      0.97      0.96       172\n",
        "     kaden-channel       0.99      0.98      0.99       176\n",
        "    livedoor-homme       0.98      0.88      0.93        95\n",
        "       movie-enter       0.96      0.99      0.98       158\n",
        "            peachy       0.94      0.98      0.96       174\n",
        "              smax       0.98      0.99      0.99       167\n",
        "      sports-watch       0.98      1.00      0.99       190\n",
        "        topic-news       0.99      0.98      0.98       163\n",
        "\n",
        "         micro avg       0.97      0.97      0.97      1473\n",
        "         macro avg       0.97      0.97      0.97      1473\n",
        "      weighted avg       0.97      0.97      0.97      1473\n",
        "    ```\n",
        "  - sklearn GradientBoostingClassifier with MeCab\n",
        "    ```\n",
        "                      precision    recall  f1-score   support\n",
        "\n",
        "    dokujo-tsushin       0.89      0.86      0.88       178\n",
        "      it-life-hack       0.91      0.90      0.91       172\n",
        "     kaden-channel       0.90      0.94      0.92       176\n",
        "    livedoor-homme       0.79      0.74      0.76        95\n",
        "       movie-enter       0.93      0.96      0.95       158\n",
        "            peachy       0.87      0.92      0.89       174\n",
        "              smax       0.99      1.00      1.00       167\n",
        "      sports-watch       0.93      0.98      0.96       190\n",
        "        topic-news       0.96      0.86      0.91       163\n",
        "\n",
        "         micro avg       0.92      0.92      0.92      1473\n",
        "         macro avg       0.91      0.91      0.91      1473\n",
        "      weighted avg       0.92      0.92      0.91      1473\n",
        "    ```\n",
        "\n",
        "- Small training data (1/5 of full training data)\n",
        "  - BERT with SentencePiece\n",
        "    ```\n",
        "                    precision    recall  f1-score   support\n",
        "\n",
        "    dokujo-tsushin       0.97      0.87      0.92       178\n",
        "      it-life-hack       0.86      0.86      0.86       172\n",
        "     kaden-channel       0.95      0.94      0.95       176\n",
        "    livedoor-homme       0.82      0.82      0.82        95\n",
        "       movie-enter       0.97      0.99      0.98       158\n",
        "            peachy       0.89      0.95      0.92       174\n",
        "              smax       0.94      0.96      0.95       167\n",
        "      sports-watch       0.97      0.97      0.97       190\n",
        "        topic-news       0.94      0.94      0.94       163\n",
        "\n",
        "         micro avg       0.93      0.93      0.93      1473\n",
        "         macro avg       0.92      0.92      0.92      1473\n",
        "      weighted avg       0.93      0.93      0.93      1473\n",
        "    ```\n",
        "  - sklearn GradientBoostingClassifier with MeCab\n",
        "    ```\n",
        "                    precision    recall  f1-score   support\n",
        "\n",
        "    dokujo-tsushin       0.82      0.71      0.76       178\n",
        "      it-life-hack       0.86      0.88      0.87       172\n",
        "     kaden-channel       0.91      0.87      0.89       176\n",
        "    livedoor-homme       0.67      0.63      0.65        95\n",
        "       movie-enter       0.87      0.95      0.91       158\n",
        "            peachy       0.70      0.78      0.73       174\n",
        "              smax       1.00      1.00      1.00       167\n",
        "      sports-watch       0.87      0.95      0.91       190\n",
        "        topic-news       0.92      0.82      0.87       163\n",
        "\n",
        "         micro avg       0.85      0.85      0.85      1473\n",
        "         macro avg       0.85      0.84      0.84      1473\n",
        "      weighted avg       0.86      0.85      0.85      1473\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk6hLbYLRDN9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hygv39z4Qxvz",
        "colab_type": "text"
      },
      "source": [
        "## オリジナルに対する追加設定\n",
        "\n",
        "下の手順で環境を自分のcolabに構築します。\n",
        "\n",
        "下の手順以外に次の設定を前提としています。\n",
        "\n",
        "- ランタイムはTPUを使用　→TPUでは時間がかかり過ぎたのでGPUに変更\n",
        "- マイドライブにyoheikikutaさんのmodelを追加しておく\n",
        "\n",
        "→yoheikikutaさんのgoogle drive\n",
        "> https://drive.google.com/drive/folders/1Zsm9DD40lrUVu6iAnIuTH2ODIkh-WM-O<br>\n",
        "\n",
        "をgoogle driveにて「マイドライブ」に追加しておく<br>\n",
        "（マイドライブ経由で直接アクセスもできるが、コピーも早いので安全策をとる）\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJP1N4UR7gPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# google driveへの接続は毎回必要\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip0MwUNSbzyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dle5S4y-7nx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bert-japaneseをgoogle driveのコード用フォルダにロード\n",
        "!git clone https://github.com/yoheikikuta/bert-japanese.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5K5eG1R7rv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/bert-japanese\n",
        "!ls -l\n",
        "!ls -l src"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F_paYRRSqMd",
        "colab_type": "text"
      },
      "source": [
        "bert-japaneseの下のフォルダ構成は\n",
        "> bert-japanese\n",
        "> - bert　　　→ フォルダのみ\n",
        "> - model　　 → フォルダのみ\n",
        "> - notebook　→ 処理には不要\n",
        "> - src\n",
        "\n",
        "のようになっている。\n",
        "- bert　　→本家のbertをgitで展開\n",
        "- model   →yoheikikutaさんのgoogle driveよりコピー\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_wih5KZcMV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bertをbertフォルダにロード\n",
        "!git clone https://github.com/google-research/bert.git\n",
        "!ls -l bert\n",
        "import sys\n",
        "sys.path.append('/content/bert-japanese/bert')\n",
        "sys.path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9XlxLL0V6fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# yoheikikutaさんのgoogle driveよりmodelファイルをコピー\n",
        "# それなり（10分程度）の時間はかかる\n",
        "%%time\n",
        "!cp /content/drive/My\\ Drive/bert-wiki-ja/*.* ./model/\n",
        "!ls -l model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAj83cpyX98S",
        "colab_type": "text"
      },
      "source": [
        "オリジナルのconfig.iniはcolab環境のフォルダ構成を\n",
        "> /work/\n",
        "\n",
        "直下にbert-japaneseが展開された想定になっているので、\n",
        "> /work/　→　/content/bert-japanese/\n",
        "\n",
        "に置き換えたconfig.iniに置換する必要がある"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57bLBg627u0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 修正したconfig.iniをアップロード\n",
        "!rm config.ini\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eje6tGsa_-aE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# カレントフォルダをsrcに移動\n",
        "%cd /content/bert-japanese/src"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4bhMl60ZcK0",
        "colab_type": "text"
      },
      "source": [
        "## ここからいよいよ実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNKQMmXFtaNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import configparser\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "import sys\n",
        "import tarfile \n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "CURDIR = os.getcwd()\n",
        "CONFIGPATH = os.path.join(CURDIR, os.pardir, 'config.ini')\n",
        "config = configparser.ConfigParser()\n",
        "config.read(CONFIGPATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y0hiZrXtaNk",
        "colab_type": "text"
      },
      "source": [
        "## Data preparing （→題材であるlivedoor記事をFine Tuningの入力用に加工する）\n",
        "\n",
        "You need execute the following cells just once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPWrh9BCtaNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FILEURL = config['FINETUNING-DATA']['FILEURL']\n",
        "FILEPATH = config['FINETUNING-DATA']['FILEPATH']\n",
        "EXTRACTDIR = config['FINETUNING-DATA']['TEXTDIR']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2crAn9vTtaNn",
        "colab_type": "text"
      },
      "source": [
        "Download and unzip data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoVQA5eRtaNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "urlretrieve(FILEURL, FILEPATH)\n",
        "\n",
        "mode = \"r:gz\"\n",
        "tar = tarfile.open(FILEPATH, mode) \n",
        "tar.extractall(EXTRACTDIR) \n",
        "tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn7fT9EutaNq",
        "colab_type": "text"
      },
      "source": [
        "Data preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97SovrYTtaNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_txt(filename):\n",
        "    with open(filename) as text_file:\n",
        "        # 0: URL, 1: timestamp\n",
        "        text = text_file.readlines()[2:]\n",
        "        text = [sentence.strip() for sentence in text]\n",
        "        text = list(filter(lambda line: line != '', text))\n",
        "        return ''.join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEqf0uPPtaN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = [ \n",
        "    name for name \n",
        "    in os.listdir( os.path.join(EXTRACTDIR, \"text\") ) \n",
        "    if os.path.isdir( os.path.join(EXTRACTDIR, \"text\", name) ) ]\n",
        "\n",
        "categories = sorted(categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmxGpk9QtaN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuNbBfKDtaN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table = str.maketrans({\n",
        "    '\\n': '',\n",
        "    '\\t': '　',\n",
        "    '\\r': '',\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jH3LqzRtaN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "all_text = []\n",
        "all_label = []\n",
        "\n",
        "for cat in categories:\n",
        "    files = glob.glob(os.path.join(EXTRACTDIR, \"text\", cat, \"{}*.txt\".format(cat)))\n",
        "    files = sorted(files)\n",
        "    body = [ extract_txt(elem).translate(table) for elem in files ]\n",
        "    label = [cat] * len(body)\n",
        "    \n",
        "    all_text.extend(body)\n",
        "    all_label.extend(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uepDu4qFtaOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'text' : all_text, 'label' : all_label})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMifhSNZtaOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3I05zPJtaOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.sample(frac=1, random_state=23).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St6uhBdBtaOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcj2zFYPtaOS",
        "colab_type": "text"
      },
      "source": [
        "Save data as tsv files.  \n",
        "test:dev:train = 2:2:6. To check the usability of finetuning, we also prepare sampled training data (1/5 of full training data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2MJJ85utaOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[:len(df) // 5].to_csv( os.path.join(EXTRACTDIR, \"test.tsv\"), sep='\\t', index=False)\n",
        "df[len(df) // 5:len(df)*2 // 5].to_csv( os.path.join(EXTRACTDIR, \"dev.tsv\"), sep='\\t', index=False)\n",
        "df[len(df)*2 // 5:].to_csv( os.path.join(EXTRACTDIR, \"train.tsv\"), sep='\\t', index=False)\n",
        "\n",
        "### 1/5 of full training data.\n",
        "# df[:len(df) // 5].to_csv( os.path.join(EXTRACTDIR, \"test.tsv\"), sep='\\t', index=False)\n",
        "# df[len(df) // 5:len(df)*2 // 5].to_csv( os.path.join(EXTRACTDIR, \"dev.tsv\"), sep='\\t', index=False)\n",
        "# df[len(df)*2 // 5:].sample(frac=0.2, random_state=23).to_csv( os.path.join(EXTRACTDIR, \"train.tsv\"), sep='\\t', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4qCUfuMtaOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRETRAINED_MODEL_PATH = '../model/model.ckpt-1400000'\n",
        "FINETUNE_OUTPUT_DIR = '../model/livedoor_output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E_shfIMtaOa",
        "colab_type": "text"
      },
      "source": [
        "## Finetune pre-trained model\n",
        "\n",
        "It will take a lot of hours to execute the following cells on CPU environment.  \n",
        "You can also use colab to recieve the power of TPU. You need to uplode the created data onto your GCS bucket.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1zZH2GWe0U-7GjJ2w2duodFfEUptvHjcx)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE9rPxrutaOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# It will take many hours on CPU environment.\n",
        "\n",
        "!python3 ../src/run_classifier.py \\\n",
        "  --task_name=livedoor \\\n",
        "  --do_train=true \\\n",
        "  --do_eval=true \\\n",
        "  --data_dir=../data/livedoor \\\n",
        "  --model_file=\"../model/wiki-ja.model\" \\\n",
        "  --vocab_file=\"../model/wiki-ja.vocab\" \\\n",
        "  --init_checkpoint={PRETRAINED_MODEL_PATH} \\\n",
        "  --max_seq_length=512 \\\n",
        "  --train_batch_size=4 \\\n",
        "  --learning_rate=2e-5 \\\n",
        "  --num_train_epochs=10 \\\n",
        "  --output_dir={FINETUNE_OUTPUT_DIR}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1PRqvjF72Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l ../model/livedoor_output\n",
        "!ls -l ../model/livedoor_output/eval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJeDbAWe-hBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fine Tuning結果をMy Driveに保存\n",
        "!cp -r ../model/livedoor_output /content/drive/My\\ Drive/Colab_Data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiC-pVDgtaOh",
        "colab_type": "text"
      },
      "source": [
        "## Predict using the finetuned model\n",
        "\n",
        "Let's predict test data using the finetuned model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_z_Dr0zEhgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fine Tuning結果をMy Driveから復元\n",
        "!cp -r /content/drive/My\\ Drive/Colab_Data/livedoor_output ../model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flkgtNfwH_p1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l ../model/livedoor_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5H0ggzMtaOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"../src\")\n",
        "\n",
        "import tokenization_sentencepiece as tokenization\n",
        "from run_classifier import LivedoorProcessor\n",
        "from run_classifier import model_fn_builder\n",
        "from run_classifier import file_based_input_fn_builder\n",
        "from run_classifier import file_based_convert_examples_to_features\n",
        "from utils import str_to_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm7nlXuZtaOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.append(\"../bert\")\n",
        "\n",
        "import modeling\n",
        "import optimization\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h_1ecovtaOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import configparser\n",
        "import json\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import tempfile\n",
        "\n",
        "bert_config_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.json')\n",
        "bert_config_file.write(json.dumps({k:str_to_value(v) for k,v in config['BERT-CONFIG'].items()}))\n",
        "bert_config_file.seek(0)\n",
        "bert_config = modeling.BertConfig.from_json_file(bert_config_file.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebzCwJsMtaOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 以下の式は問題あり。文字列をSORTしているので数字の桁上がりの考慮がないためlatestになっていない\n",
        "# フォルダ内を確認して、場合によっては FINETUNED_MODEL_PATH を手で修正する\n",
        "output_ckpts = glob.glob(\"{}/model.ckpt*data*\".format(FINETUNE_OUTPUT_DIR))\n",
        "latest_ckpt = sorted(output_ckpts)[-1]\n",
        "FINETUNED_MODEL_PATH = latest_ckpt.split('.data-00000-of-00001')[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8efYDX8XtaOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FLAGS(object):\n",
        "    '''Parameters.'''\n",
        "    def __init__(self):\n",
        "        self.model_file = \"../model/wiki-ja.model\"\n",
        "        self.vocab_file = \"../model/wiki-ja.vocab\"\n",
        "        self.do_lower_case = True\n",
        "        self.use_tpu = False\n",
        "        self.output_dir = \"/dummy\"\n",
        "        self.data_dir = \"../data/livedoor\"\n",
        "        self.max_seq_length = 512\n",
        "        self.init_checkpoint = FINETUNED_MODEL_PATH\n",
        "        self.predict_batch_size = 4\n",
        "        \n",
        "        # The following parameters are not used in predictions.\n",
        "        # Just use to create RunConfig.\n",
        "        self.master = None\n",
        "        self.save_checkpoints_steps = 1\n",
        "        self.iterations_per_loop = 1\n",
        "        self.num_tpu_cores = 1\n",
        "        self.learning_rate = 0\n",
        "        self.num_warmup_steps = 0\n",
        "        self.num_train_steps = 0\n",
        "        self.train_batch_size = 0\n",
        "        self.eval_batch_size = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1SRq4cDtaOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FLAGS = FLAGS()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKbo1dNBtaO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processor = LivedoorProcessor()\n",
        "label_list = processor.get_labels()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5qi9BU9taO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tokenization.FullTokenizer(\n",
        "    model_file=FLAGS.model_file, vocab_file=FLAGS.vocab_file,\n",
        "    do_lower_case=FLAGS.do_lower_case)\n",
        "\n",
        "tpu_cluster_resolver = None\n",
        "\n",
        "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    master=FLAGS.master,\n",
        "    model_dir=FLAGS.output_dir,\n",
        "    save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=FLAGS.iterations_per_loop,\n",
        "        num_shards=FLAGS.num_tpu_cores,\n",
        "        per_host_input_for_training=is_per_host))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbYTq2vPtaO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "    bert_config=bert_config,\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=FLAGS.init_checkpoint,\n",
        "    learning_rate=FLAGS.learning_rate,\n",
        "    num_train_steps=FLAGS.num_train_steps,\n",
        "    num_warmup_steps=FLAGS.num_warmup_steps,\n",
        "    use_tpu=FLAGS.use_tpu,\n",
        "    use_one_hot_embeddings=FLAGS.use_tpu)\n",
        "\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=FLAGS.use_tpu,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=FLAGS.train_batch_size,\n",
        "    eval_batch_size=FLAGS.eval_batch_size,\n",
        "    predict_batch_size=FLAGS.predict_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIsTjB-wtaO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_examples = processor.get_test_examples(FLAGS.data_dir)\n",
        "predict_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.tf_record')\n",
        "\n",
        "file_based_convert_examples_to_features(predict_examples, label_list,\n",
        "                                        FLAGS.max_seq_length, tokenizer,\n",
        "                                        predict_file.name)\n",
        "\n",
        "predict_drop_remainder = True if FLAGS.use_tpu else False\n",
        "\n",
        "predict_input_fn = file_based_input_fn_builder(\n",
        "    input_file=predict_file.name,\n",
        "    seq_length=FLAGS.max_seq_length,\n",
        "    is_training=False,\n",
        "    drop_remainder=predict_drop_remainder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCsO0QaMtaO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = estimator.predict(input_fn=predict_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TuoHURFQtaO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# It will take a few hours on CPU environment.\n",
        "\n",
        "result = list(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7TyQa-BtaO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-JGK28VtaPB",
        "colab_type": "text"
      },
      "source": [
        "Read test data set and add prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkRMkyDJtaPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_y43MpUtaPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv(\"../data/livedoor/test.tsv\", sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQOxlw0etaPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['predict'] = [ label_list[elem['probabilities'].argmax()] for elem in result ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP8p5FVntaPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckCSD4ZUtaPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum( test_df['label'] == test_df['predict'] ) / len(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP1ZcwEitaPm",
        "colab_type": "text"
      },
      "source": [
        "A littel more detailed check using `sklearn.metrics`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlM25hMNtaPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scikit-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzYqiJTHtaPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsLuazV4taPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(test_df['label'], test_df['predict']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM26ejf2taPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(test_df['label'], test_df['predict']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuHaey4RtaPx",
        "colab_type": "text"
      },
      "source": [
        "### Simple baseline model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoOqrIsXtaPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4FI-72ttaPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(\"../data/livedoor/train.tsv\", sep='\\t')\n",
        "dev_df = pd.read_csv(\"../data/livedoor/dev.tsv\", sep='\\t')\n",
        "test_df = pd.read_csv(\"../data/livedoor/test.tsv\", sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0hA5wxktaP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -q -y mecab libmecab-dev mecab-ipadic mecab-ipadic-utf8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDpFJEfbtaP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mecab-python3==0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nU-I96WtaP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import MeCab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqXiHPFetaP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = MeCab.Tagger(\"-Owakati\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nifszS9mtaQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dev_df = pd.concat([train_df, dev_df])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6UIukSXtaQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dev_xs = train_dev_df['text'].apply(lambda x: m.parse(x))\n",
        "train_dev_ys = train_dev_df['label']\n",
        "\n",
        "test_xs = test_df['text'].apply(lambda x: m.parse(x))\n",
        "test_ys = test_df['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v8amw3qtaQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=750)\n",
        "train_dev_xs_ = vectorizer.fit_transform(train_dev_xs)\n",
        "test_xs_ = vectorizer.transform(test_xs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFVYwgPbtaQG",
        "colab_type": "text"
      },
      "source": [
        "The following set up is not exactly identical to that of BERT because inside Classifier it uses `train_test_split` with shuffle.  \n",
        "In addition, parameters are not well tuned, however, we think it's enough to check the power of BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH8J9S6ktaQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "model = GradientBoostingClassifier(n_estimators=200,\n",
        "                                   validation_fraction=len(dev_df)/len(train_df),\n",
        "                                   n_iter_no_change=5,\n",
        "                                   tol=0.01,\n",
        "                                   random_state=23)\n",
        "\n",
        "### 1/5 of full training data.\n",
        "# model = GradientBoostingClassifier(n_estimators=200,\n",
        "#                                    validation_fraction=len(dev_df)/len(train_df),\n",
        "#                                    n_iter_no_change=5,\n",
        "#                                    tol=0.01,\n",
        "#                                    random_state=23)\n",
        "\n",
        "model.fit(train_dev_xs_, train_dev_ys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpaVkI38taQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(test_ys, model.predict(test_xs_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqqJvQvetaQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(test_ys, model.predict(test_xs_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfbFhlLQtaQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}